{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Apache_Beam_Workspace.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNQlMxaffig+SwV9bS+dpwW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gurucl/apache_beam_tutorial/blob/main/Apache_Beam_Workspace.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('hello world!')"
      ],
      "metadata": {
        "id": "f9YvCFvzEnkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFiltdYwDd27"
      },
      "outputs": [],
      "source": [
        "! pip3 install apache_beam"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pwd\n",
        "! ls -lrt sample_data"
      ],
      "metadata": {
        "id": "gBVZxPEJEt8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import apache_beam as beam\n",
        "p1 = beam.Pipeline()\n",
        "output = ( p1 \n",
        "          | beam.io.ReadFromText(\"/content/sample_data/tiny_movies.csv\", skip_header_lines=1)\n",
        "          | beam.Map(lambda x: x.split(\",\"))\n",
        "       #   | beam.Sample.FixedSizeGlobally(5)\n",
        "         | beam.Filter(lambda x: float(x[3].strip()) > 8.8)\n",
        "        # | beam.io.WriteToText(\"sample_data/output\", \"result\", num_shards=3, header = \"Movie ID, Movie_Name, Year, Rating\", compression_type = beam.io.filesystem.CompressionTypes.GZIP )\n",
        "         | beam.Map(print)\n",
        "          )\n",
        "p1.run()"
      ],
      "metadata": {
        "id": "7zVcG0LaKqgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import apache_beam as beam\n",
        "p1 = beam.Pipeline()\n",
        "\n",
        "schema1 = \"\"\" {\n",
        "   \"type\" : \"record\",\n",
        "   \"namespace\" : \"Tutorialspoint\",\n",
        "   \"name\" : \"Employee\",\n",
        "   \"fields\" : [\n",
        "      { \"name\" : \"Movie_id\" , \"type\" : \"string\" },\n",
        "      { \"name\" : \"Name\" , \"type\" : \"string\" },\n",
        "      { \"name\" : \"Year\" , \"type\" : \"string\" },\n",
        "      { \"name\" : \"Rating\" , \"type\" : \"string\" }\n",
        "   ]\n",
        "}\"\"\"\n",
        "output = ( p1 \n",
        "          | beam.io.ReadFromText(\"/content/sample_data/tiny_movies.csv\", skip_header_lines=1)\n",
        "          | beam.Map(lambda x: x.split(\",\"))\n",
        "       #   | beam.Sample.FixedSizeGlobally(5)\n",
        "         | beam.Filter(lambda x: float(x[3].strip()) > 8.8)\n",
        "        # | beam.io.WriteToText(\"sample_data/output\", \"result\", shard_name_template='-SS-NN', num_shards=3, header = \"Movie ID, Movie_Name, Year, Rating\", )\n",
        "          | beam.io.WriteToAvro(\"out\", schema = schema1)\n",
        "        # | beam.Map(print)\n",
        "          )\n",
        "p1.run()"
      ],
      "metadata": {
        "id": "CGR5D74bEGEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cat sample_data/tiny_movies.csv"
      ],
      "metadata": {
        "id": "lBggsGyHBdSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import apache_beam as beam\n",
        "\n",
        "p1 = beam.Pipeline()\n",
        "\n",
        "result = (p1\n",
        "        | beam.Create([1,2,3,4,5,6,7,8,9,10])\n",
        "      #   | beam.Filter(lambda x: x%2==0)\n",
        "       | beam.Map(print)\n",
        "          )\n",
        "p1.run()\n",
        "\n"
      ],
      "metadata": {
        "id": "KoODh6f8K0L1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import apache_beam as beam\n",
        "import re\n",
        "\n",
        "p1 = beam.Pipeline()\n",
        "\n",
        "list = [\"K\", \"G\", \"F\", \"Kolar\", \"and\", \"to\"]\n",
        "\n",
        "def get_details(str):\n",
        "  return True if str in list else False\n",
        "  # if str in list:\n",
        "  #   return True\n",
        "\n",
        "class FlattenData(beam.DoFn):\n",
        "  def process(self, element):\n",
        "    return re.findall('[a-zA-Z]+', element)\n",
        "\n",
        "class FilterData(beam.DoFn):\n",
        "  def process(self, element):\n",
        "    if element in list:\n",
        "      return [element]\n",
        "  \n",
        "class GroupeData(beam.DoFn):\n",
        "  def process(self, element):\n",
        "    return [(element,1)]\n",
        "  \n",
        "\n",
        "class CalcResult(beam.DoFn):\n",
        "  def process(self, element):\n",
        "    (key, value) = element\n",
        "    return [(key, sum(value))]\n",
        "\n",
        "result = (\n",
        "    p1\n",
        "    | beam.io.ReadFromText(\"/content/sample_data/kgf_2.txt\")\n",
        "  # | beam.FlatMap(lambda x: re.findall('[a-zA-Z]+', x))\n",
        "    | beam.ParDo(FlattenData())\n",
        "  # | beam.Filter(get_details)\n",
        "    | beam.ParDo(FilterData())\n",
        "  # | beam.Map(lambda x: (x,1))\n",
        "    | beam.ParDo(GroupeData())\n",
        "  # | beam.CombinePerKey(sum)\n",
        "    | beam.GroupByKey()\n",
        "    | beam.ParDo(CalcResult())\n",
        "     | beam.Map(print)\n",
        "  #  | beam.io.WriteToText(\"/content/sample_data/words_output\")\n",
        "    \n",
        ")\n",
        "p1.run()\n",
        "\n"
      ],
      "metadata": {
        "id": "3_caLs_IV2Qq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import apache_beam as beam\n",
        "\n",
        "p1 = beam.Pipeline()\n",
        "\n",
        "movies_data = [\n",
        "               (1,\"Avenger\"),\n",
        "               (2,\"Infinity War\"),\n",
        "               (3,\"Winter Soldier\"),\n",
        "               (4,\"Thor - dark World\")\n",
        "]\n",
        "ratings_data = [\n",
        "                (1, 8.5),\n",
        "                (2, 9.1),\n",
        "                (3, 7.5),\n",
        "                (1, 8.9),\n",
        "                (2, 9.2) \n",
        "]\n",
        "\n",
        "movies = p1 |'reading Movies data' >> beam.Create(movies_data)\n",
        "ratings = p1 |'reading Ratings data' >> beam.Create(ratings_data)\n",
        "\n",
        "# joined_data = ( {'movie_name':movies, 'movie_ratings':ratings} \n",
        "#                |  beam.CoGroupByKey())  | beam.Map(print)\n",
        "#              #  | beam.Map(lambda x: (x[0], x[1][1][0], x[1][0]))\n",
        "              \n",
        "joined_data = ( {movies, ratings} \n",
        "               |  beam.CoGroupByKey()) | beam.Map(lambda x: (x[0], x[1][1][0], x[1][0], sum(x[1][0]), sum(x[1][0])/len(x[1][0]) if len(x[1][0])!=0 else 0 ))| beam.Map(print)\n",
        "\n",
        "p1.run()"
      ],
      "metadata": {
        "id": "l6Wbj2gxc11J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import apache_beam as beam\n",
        "\n",
        "\n",
        "p1 = beam.Pipeline()\n",
        "\n",
        "def my_partition_fn(element, num_partitions):\n",
        "  return 0 if element%2==0 else 1\n",
        "\n",
        "result = (p1\n",
        "          | beam.Create(range(1,11))\n",
        "          | beam.Partition(my_partition_fn, 2)\n",
        "        )\n",
        "# result[1] | 'Printing records from First Partition' >> beam.Map(print)\n",
        "result[0] | 'Printing records from Second Partition' >>  beam.Map(print)\n",
        "\n",
        "p1.run()"
      ],
      "metadata": {
        "id": "tAHW6T__ijhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import apache_beam as beam\n",
        "\n",
        "p1 = beam.Pipeline()\n",
        "\n",
        "odd = [1,3,5,7,9]\n",
        "even = [2,4,6,8]\n",
        "name = ['Ram', 'Rahim', 'Robert' ]\n",
        "\n",
        "odd_p1 = (p1| 'creating Odd PCollection' >> beam.Create(odd))\n",
        "even_p1 = (p1| 'creating Even PCollection' >> beam.Create(even))\n",
        "name_p1 = (p1| 'creating Name PCollection' >> beam.Create(name))\n",
        "\n",
        "( {odd_p1, even_p1, name_p1} | beam.Flatten()) | beam.Map(print)\n",
        "\n",
        "p1.run()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LRiN6J2YkW6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import apache_beam as beam\n",
        "\n",
        "p1 = beam.Pipeline()\n",
        "\n",
        "class My_PTransform(beam.PTransform):\n",
        "  def expand(self, input_collection):\n",
        "    result = (input_collection | beam.Map(lambda x: f\"{x[0]} has received {x[2]} marks\"))\n",
        "    return result\n",
        "\n",
        "students_data = (p1\n",
        "                | beam.io.ReadFromText(\"/content/sample_data/student_marks.csv\")\n",
        "                | beam.Map(lambda x: x.split(\",\"))\n",
        "                | beam.Map(lambda x: (x[0], x[1], int(x[2]) + int(x[3]) + int(x[4]) ))\n",
        "                )\n",
        "\n",
        "us_students_data = (students_data \n",
        "                    |'Filtering US Student records' >> beam.Filter(lambda x: x[1].strip() == 'US') \n",
        "                 #   | 'Printing the US Student Records' >> beam.Map(print)\n",
        "                # | beam.Map(lambda x: f\"{x[0]} has received {x[2]} marks\")\n",
        "                | 'Applying My transformations to US student Records' >> My_PTransform()\n",
        "                 | 'Writing US Student Records' >> beam.io.WriteToText(\"/content/sample_data/us_students_data\", num_shards = 1)\n",
        "                    )\n",
        "\n",
        "in_students_data = (students_data \n",
        "                    | 'Filtering IN Student records' >> beam.Filter(lambda x: x[1].strip() == 'IN') \n",
        "                  #  | 'Printing the IN Student Records' >>  beam.Map(print)\n",
        "                 # | beam.Map(lambda x: f\"{x[0]} has received {x[2]} marks\")\n",
        "                 | 'Applying My transformations to IN student Records' >> My_PTransform()\n",
        "                  |'Writing IN Student Records' >> beam.io.WriteToText(\"/content/sample_data/in_students_data\", num_shards = 1)\n",
        "                    )\n",
        "\n",
        "p1.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3BiYlr4kpcf",
        "outputId": "777d1fcb-e5c3-4cea-9818-cfa7c91b8f67"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7f76a6b6bed0>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from apache_beam import pvalue\n",
        "from apache_beam.typehints.decorators import with_output_types\n",
        "import apache_beam as beam\n",
        "\n",
        "p1 = beam.Pipeline()\n",
        "\n",
        "side_list = []\n",
        "with open(\"/content/sample_data/exclude_employee.txt\", 'r') as file:\n",
        "  for id in file:\n",
        "    side_list.append(int(id.strip()))\n",
        "print(side_list)\n",
        "\n",
        "class SpitRows(beam.DoFn):\n",
        "  def process(self, element):\n",
        "    return [element.split(\",\")]\n",
        "\n",
        "class GetFields(beam.DoFn):\n",
        "  def process(self, element, ex_data):\n",
        "    fields = element.split(\",\")\n",
        "    if int(fields[0]) not in ex_data:\n",
        "      return [fields]\n",
        "\n",
        "class PartitionedData(beam.DoFn):\n",
        "  def process(self, element, dept, sal):\n",
        "    if element[4] == dept:\n",
        "      yield beam.pvalue.TaggedOutput('DPL_Data', element)\n",
        "    else:\n",
        "      yield beam.pvalue.TaggedOutput('Non_DPL_Data', element)\n",
        "    if int(element[3]) > sal:\n",
        "      yield [element]\n",
        "\n",
        "\n",
        "employee_data = (p1\n",
        "                 | beam.io.ReadFromText(\"/content/sample_data/employee.csv\", skip_header_lines=1)\n",
        "              #  | beam.ParDo(GetFields(), side_list)\n",
        "              #  | beam.io.WriteToText(\"sample_data/employee_output_data\")\n",
        "                 | beam.ParDo(SpitRows())\n",
        "                 | beam.ParDo(PartitionedData(), dept='DPL', sal=1000).with_outputs('DPL_Data', 'Non_DPL_Data', main='Elites')\n",
        "                 )\n",
        "\n",
        "DPL_Data = employee_data.DPL_Data\n",
        "Non_DPL_Data = employee_data.Non_DPL_Data\n",
        "Elites_Data = employee_data.Elites\n",
        "\n",
        "DPL_Data | 'Writing DPL Data' >> beam.io.WriteToText('sample_data/dpl_data', num_shards=1)\n",
        "Non_DPL_Data | 'Writing Non-DPL Data' >> beam.io.WriteToText('sample_data/non_dpl_data', num_shards=1)\n",
        "Elites_Data | 'Writing Elites Data' >> beam.io.WriteToText('sample_data/elites_data', num_shards=1)\n",
        "\n",
        "p1.run()\n"
      ],
      "metadata": {
        "id": "IfAZzlhUrjv4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14db28b6-d45f-4857-f5ad-1402b8f5052f"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 3, 7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n",
            "WARNING:apache_beam.io.filebasedsink:Deleting 1 existing files in target path matching: -*-of-%(num_shards)05d\n",
            "WARNING:apache_beam.io.filebasedsink:Deleting 1 existing files in target path matching: -*-of-%(num_shards)05d\n",
            "WARNING:apache_beam.io.filebasedsink:Deleting 1 existing files in target path matching: -*-of-%(num_shards)05d\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7f76a5a58ad0>"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pwd\n",
        "! ls /content/sample_data\n",
        "# ! rm -rf /content/sample_data/beam-temp-*"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVo7mS1y8E4U",
        "outputId": "88f08936-7e09-47a8-869a-b9f285204165"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "anscombe.json\t\t\t     kgf_2.txt\n",
            "california_housing_test.csv\t     mnist_test.csv\n",
            "california_housing_train.csv\t     mnist_train_small.csv\n",
            "dpl_data-00000-of-00001\t\t     non_dpl_data-00000-of-00001\n",
            "elites_data-00000-of-00001\t     README.md\n",
            "employee.csv\t\t\t     student_marks.csv\n",
            "employee_output_data-00000-of-00001  tiny_movies.csv\n",
            "exclude_employee.txt\t\t     us_students_data-00000-of-00001\n",
            "in_students_data-00000-of-00001\n"
          ]
        }
      ]
    }
  ]
}